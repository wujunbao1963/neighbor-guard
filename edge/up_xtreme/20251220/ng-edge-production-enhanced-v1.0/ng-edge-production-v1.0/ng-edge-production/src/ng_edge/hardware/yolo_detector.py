"""
YOLO æ£€æµ‹å™¨ - é’ˆå¯¹ Reolink è¶…å®½å±æ‘„åƒå¤´ä¼˜åŒ–

åŸºäºç ”ç©¶è®ºæ–‡çš„æœ€ä½³å®è·µ:
1. åŒºåŸŸåˆ†å‰²æ£€æµ‹ (é¿å…è¶…å®½å±ç•¸å˜)
2. ä½¿ç”¨é¢„è®­ç»ƒ COCO æ¨¡å‹
3. YOLOv11n (æœ€å¿«ã€CPU å‹å¥½)
"""

import cv2
import numpy as np
from typing import List, Optional, Tuple, Dict
from dataclasses import dataclass
from datetime import datetime
import time

# Ultralytics YOLO
try:
    from ultralytics import YOLO
    HAS_YOLO = True
except ImportError:
    HAS_YOLO = False
    print("[WARN] ultralytics not installed. Install: pip install ultralytics")


@dataclass
class Detection:
    """æ£€æµ‹ç»“æœ"""
    class_id: int
    class_name: str
    confidence: float
    bbox: Tuple[int, int, int, int]  # (x, y, w, h)
    region_index: Optional[int] = None  # æ¥è‡ªå“ªä¸ªåŒºåŸŸ


class YOLODetector:
    """
    YOLO æ£€æµ‹å™¨
    
    é’ˆå¯¹è¶…å®½å±ä¼˜åŒ–:
    - æ”¯æŒåŒºåŸŸæ£€æµ‹
    - ç±»è¿‡æ»¤ (åªè¦ person, car)
    - ç½®ä¿¡åº¦é˜ˆå€¼
    """
    
    def __init__(
        self,
        model_name: str = "yolo11n.pt",
        conf_threshold: float = 0.5,
        target_classes: List[str] = None,
        device: str = "cpu",
    ):
        """
        Args:
            model_name: YOLO æ¨¡å‹åç§°
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            target_classes: ç›®æ ‡ç±»åˆ«ï¼ˆNone = æ‰€æœ‰ç±»åˆ«ï¼‰
            device: 'cpu' æˆ– 'cuda'
        """
        if not HAS_YOLO:
            raise RuntimeError("ultralytics not installed")
        
        self.model_name = model_name
        self.conf_threshold = conf_threshold
        self.target_classes = target_classes or ["person", "car"]
        self.device = device
        
        # åŠ è½½æ¨¡å‹
        print(f"[YOLO] åŠ è½½æ¨¡å‹: {model_name}")
        self.model = YOLO(model_name)
        
        # ç§»åŠ¨åˆ°è®¾å¤‡
        if device == "cuda":
            self.model.to("cuda")
        
        # COCO ç±»åˆ«
        self.class_names = self.model.names  # {0: 'person', 2: 'car', ...}
        
        # è¿‡æ»¤ç±»åˆ« ID
        self.target_class_ids = []
        for class_id, class_name in self.class_names.items():
            if class_name in self.target_classes:
                self.target_class_ids.append(class_id)
        
        print(f"[YOLO] ç›®æ ‡ç±»åˆ«: {self.target_classes}")
        print(f"[YOLO] ç›®æ ‡ç±»åˆ« ID: {self.target_class_ids}")
        print(f"[YOLO] ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
        print(f"[YOLO] è®¾å¤‡: {device}")
        
        # ç»Ÿè®¡
        self.frame_count = 0
        self.detection_count = 0
        self.total_inference_time = 0.0
    
    def detect(
        self,
        frame: np.ndarray,
        visualize: bool = False
    ) -> Tuple[List[Detection], Optional[np.ndarray]]:
        """
        å•å¸§æ£€æµ‹
        
        Args:
            frame: è¾“å…¥å¸§
            visualize: æ˜¯å¦è¿”å›å¯è§†åŒ–ç»“æœ
        
        Returns:
            (detections, vis_frame)
        """
        start_time = time.time()
        
        # YOLO æ¨ç†
        results = self.model(
            frame,
            conf=self.conf_threshold,
            classes=self.target_class_ids,
            verbose=False,
        )
        
        inference_time = time.time() - start_time
        self.total_inference_time += inference_time
        self.frame_count += 1
        
        # è§£æç»“æœ
        detections = []
        
        for result in results:
            boxes = result.boxes
            
            for i in range(len(boxes)):
                class_id = int(boxes.cls[i])
                confidence = float(boxes.conf[i])
                bbox_xyxy = boxes.xyxy[i].cpu().numpy()
                
                # è½¬æ¢ä¸º (x, y, w, h)
                x1, y1, x2, y2 = bbox_xyxy
                x, y = int(x1), int(y1)
                w, h = int(x2 - x1), int(y2 - y1)
                
                detection = Detection(
                    class_id=class_id,
                    class_name=self.class_names[class_id],
                    confidence=confidence,
                    bbox=(x, y, w, h),
                )
                
                detections.append(detection)
                self.detection_count += 1
        
        # å¯è§†åŒ–
        vis_frame = None
        if visualize and len(detections) > 0:
            vis_frame = frame.copy()
            for det in detections:
                x, y, w, h = det.bbox
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                color = (0, 255, 0) if det.class_name == "person" else (255, 0, 0)
                cv2.rectangle(vis_frame, (x, y), (x+w, y+h), color, 2)
                
                # ç»˜åˆ¶æ ‡ç­¾
                label = f"{det.class_name} {det.confidence:.2f}"
                cv2.putText(
                    vis_frame, label,
                    (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    color,
                    2
                )
        
        return detections, vis_frame
    
    def detect_regions(
        self,
        regions: List[np.ndarray],
        region_offsets: List[Tuple[int, int]],
        visualize: bool = False
    ) -> Tuple[List[Detection], Optional[np.ndarray]]:
        """
        å¤šåŒºåŸŸæ£€æµ‹ï¼ˆè¶…å®½å±ä¼˜åŒ–ï¼‰
        
        Args:
            regions: åŒºåŸŸå¸§åˆ—è¡¨
            region_offsets: æ¯ä¸ªåŒºåŸŸçš„åç§»é‡ [(x_offset, y_offset), ...]
            visualize: æ˜¯å¦è¿”å›å¯è§†åŒ–ç»“æœ
        
        Returns:
            (detections, vis_frame) - æ‰€æœ‰æ£€æµ‹ç»“æœï¼Œåæ ‡å·²æ˜ å°„å›å®Œæ•´ç”»é¢
        """
        all_detections = []
        vis_frames = [] if visualize else None
        
        for region_idx, (region, offset) in enumerate(zip(regions, region_offsets)):
            # æ£€æµ‹å•ä¸ªåŒºåŸŸ
            detections, vis_frame = self.detect(region, visualize=visualize)
            
            # æ˜ å°„åæ ‡åˆ°å®Œæ•´ç”»é¢
            x_offset, y_offset = offset
            for det in detections:
                x, y, w, h = det.bbox
                det.bbox = (x + x_offset, y + y_offset, w, h)
                det.region_index = region_idx
            
            all_detections.extend(detections)
            
            if visualize and vis_frame is not None:
                vis_frames.append(vis_frame)
        
        # æ‹¼æ¥å¯è§†åŒ–ç»“æœ
        combined_vis = None
        if visualize and vis_frames:
            combined_vis = np.hstack(vis_frames)
        
        return all_detections, combined_vis
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        avg_fps = 0
        if self.total_inference_time > 0:
            avg_fps = self.frame_count / self.total_inference_time
        
        return {
            "frame_count": self.frame_count,
            "detection_count": self.detection_count,
            "total_inference_time": self.total_inference_time,
            "avg_inference_time": self.total_inference_time / self.frame_count if self.frame_count > 0 else 0,
            "avg_fps": avg_fps,
        }


def test_yolo_detector():
    """æµ‹è¯• YOLO æ£€æµ‹å™¨"""
    print("\n" + "=" * 70)
    print("ğŸ¯ YOLO æ£€æµ‹å™¨æµ‹è¯•")
    print("=" * 70)
    
    if not HAS_YOLO:
        print("\nâŒ ultralytics æœªå®‰è£…")
        print("   å®‰è£…: pip install ultralytics")
        return False
    
    # åˆ›å»ºæ£€æµ‹å™¨
    print("\n[1/3] åˆ›å»ºæ£€æµ‹å™¨...")
    try:
        detector = YOLODetector(
            model_name="yolo11n.pt",  # Nano æ¨¡å‹ï¼ˆæœ€å¿«ï¼‰
            conf_threshold=0.5,
            target_classes=["person", "car"],
            device="cpu",
        )
        print("âœ… æ£€æµ‹å™¨åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ£€æµ‹å™¨åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # åŠ è½½æµ‹è¯•å›¾ç‰‡
    print("\n[2/3] åŠ è½½æµ‹è¯•å›¾ç‰‡...")
    
    # å°è¯•åŠ è½½ä¹‹å‰ä¿å­˜çš„æµ‹è¯•å¸§
    test_images = [
        "/tmp/reolink_ultrawide_test/frame_original_20251219_122524.jpg",
        "/tmp/reolink_ultrawide_test/frame_region0_20251219_122524.jpg",
        "/tmp/reolink_ultrawide_test/frame_region1_20251219_122524.jpg",
        "/tmp/reolink_ultrawide_test/frame_region2_20251219_122524.jpg",
    ]
    
    test_frame = None
    for img_path in test_images:
        try:
            test_frame = cv2.imread(img_path)
            if test_frame is not None:
                print(f"âœ… åŠ è½½å›¾ç‰‡: {img_path}")
                print(f"   åˆ†è¾¨ç‡: {test_frame.shape}")
                break
        except:
            continue
    
    if test_frame is None:
        print("âŒ æ— æ³•åŠ è½½æµ‹è¯•å›¾ç‰‡")
        print("   è¯·å…ˆè¿è¡Œ reolink_ultrawide.py ç”Ÿæˆæµ‹è¯•å›¾ç‰‡")
        return False
    
    # è¿è¡Œæ£€æµ‹
    print("\n[3/3] è¿è¡Œæ£€æµ‹...")
    detections, vis_frame = detector.detect(test_frame, visualize=True)
    
    print(f"\næ£€æµ‹ç»“æœ:")
    print(f"   æ£€æµ‹åˆ° {len(detections)} ä¸ªå¯¹è±¡")
    
    for i, det in enumerate(detections, 1):
        print(f"   {i}. {det.class_name}: {det.confidence:.3f} @ {det.bbox}")
    
    # ä¿å­˜ç»“æœ
    if vis_frame is not None:
        output_path = "/tmp/reolink_ultrawide_test/yolo_detection_result.jpg"
        cv2.imwrite(output_path, vis_frame)
        print(f"\nâœ… æ£€æµ‹ç»“æœå·²ä¿å­˜: {output_path}")
    
    # ç»Ÿè®¡
    stats = detector.get_stats()
    print(f"\nç»Ÿè®¡ä¿¡æ¯:")
    print(f"   å¤„ç†å¸§æ•°: {stats['frame_count']}")
    print(f"   æ£€æµ‹æ•°é‡: {stats['detection_count']}")
    print(f"   å¹³å‡æ¨ç†æ—¶é—´: {stats['avg_inference_time']*1000:.1f}ms")
    print(f"   å¹³å‡ FPS: {stats['avg_fps']:.1f}")
    
    print("\n" + "=" * 70)
    print("âœ… YOLO æ£€æµ‹å™¨æµ‹è¯•å®Œæˆï¼")
    print("=" * 70)
    
    return True


if __name__ == "__main__":
    import sys
    
    try:
        success = test_yolo_detector()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
